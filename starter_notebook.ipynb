{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f38066af7626d035",
   "metadata": {},
   "source": [
    "# üêï Chihuahua vs üßÅ Muffin Classification - Hackathon Starter Notebook\n",
    "\n",
    "## Quick Start Guide\n",
    "\n",
    "Welcome to the **3LC x AWS Cloud Club @ UT Dallas Hackathon**! This notebook guides you through training an image classifier using **3LC** for data-centric AI.\n",
    "\n",
    "**üìã Prerequisites:** Before running this notebook, complete the setup instructions in **Cell 1** below (scroll down).\n",
    "\n",
    "### What You'll Learn:\n",
    "1. **Environment Setup** - Verify and configure your environment\n",
    "2. **Dataset Registration** - Create 3LC Tables for data versioning\n",
    "3. **Model Training** - Train ResNet-18 with automatic experiment tracking\n",
    "4. **Metrics Collection** - Analyze per-sample performance and embeddings\n",
    "5. **Iterative Improvement** - Use 3LC Dashboard to improve data quality\n",
    "\n",
    "### About 3LC (Three Lines of Code)\n",
    "3LC is a data-centric AI platform that enables the **train-fix-retrain loop**:\n",
    "- **Train** - Track experiments automatically\n",
    "- **Analyze** - Use Dashboard to find data issues  \n",
    "- **Fix** - Correct labels and improve quality\n",
    "- **Retrain** - Iterate with better data\n",
    "\n",
    "This workflow is how production AI teams achieve high accuracy with limited data!\n",
    "\n",
    "### Dataset: Chihuahua vs Muffin  \n",
    "Can you tell them apart? Your model will learn to classify:\n",
    "- üêï **Chihuahua** - Small dog breed\n",
    "- üßÅ **Muffin** - Baked good (surprisingly similar!)\n",
    "- ‚ùì **Undefined** - Ambiguous cases for later labeling\n",
    "\n",
    "### Notebook Structure:\n",
    "This notebook combines the logic from these scripts:\n",
    "- `register_tables.py` - Dataset registration with 3LC Tables\n",
    "- `train.py` - Training ResNet-18 with full 3LC integration\n",
    "\n",
    "**Let's begin!** üöÄ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c196a7f2b905b34",
   "metadata": {},
   "source": [
    "---\n",
    "# Environment Setup Instructions\n",
    "\n",
    "## Before You Begin\n",
    "\n",
    "This notebook uses **3LC** for data-centric AI workflows. Follow these one-time setup steps:\n",
    "\n",
    "### Step 0: Download the Dataset ‚ö†Ô∏è\n",
    "\n",
    "**IMPORTANT:** Before running this notebook, download the dataset using AWS CLI (no AWS account required).\n",
    "\n",
    "---\n",
    "\n",
    "#### A. Install AWS CLI (skip if already installed)\n",
    "\n",
    "**Check if installed:**\n",
    "Open a terminal and run:\n",
    "```bash\n",
    "aws --version\n",
    "```\n",
    "\n",
    "If you see a version number, skip to Step B. Otherwise, install it:\n",
    "\n",
    "**Windows:**\n",
    "1. Download the installer: [AWS CLI Windows Installer](https://awscli.amazonaws.com/AWSCLIV2.msi)\n",
    "2. Run the installer (accept all defaults)\n",
    "3. **Important:** Close and reopen your terminal/command prompt after installation\n",
    "4. Verify: `aws --version`\n",
    "\n",
    "**Mac:**\n",
    "```bash\n",
    "brew install awscli\n",
    "```\n",
    "\n",
    "**Linux:**\n",
    "```bash\n",
    "# Ubuntu/Debian\n",
    "sudo apt install awscli\n",
    "\n",
    "# RHEL/CentOS\n",
    "sudo yum install aws-cli\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### B. Download the Dataset\n",
    "\n",
    "Open a terminal/command prompt and navigate to the directory where you cloned this starter kit:\n",
    "\n",
    "**Windows (PowerShell):**\n",
    "```bash\n",
    "cd C:\\path\\to\\3lc-chihuahua-muffin-starter\n",
    "aws s3 sync s3://3lc-hackathons/muffin-chihuahua/train128 ./train128 --no-sign-request\n",
    "aws s3 sync s3://3lc-hackathons/muffin-chihuahua/test128 ./test128 --no-sign-request\n",
    "```\n",
    "\n",
    "**Mac/Linux:**\n",
    "```bash\n",
    "cd /path/to/3lc-chihuahua-muffin-starter\n",
    "aws s3 sync s3://3lc-hackathons/muffin-chihuahua/train128 ./train128 --no-sign-request\n",
    "aws s3 sync s3://3lc-hackathons/muffin-chihuahua/test128 ./test128 --no-sign-request\n",
    "```\n",
    "\n",
    "**What this does:**\n",
    "- Downloads `train128/` and `test128/` folders directly into your current directory (no intermediate folders)\n",
    "- The `--no-sign-request` flag means you don't need an AWS account\n",
    "- Download size: ~150 MB (may take 2-5 minutes depending on internet speed)\n",
    "\n",
    "---\n",
    "\n",
    "#### C. Verify Download\n",
    "\n",
    "After download completes, check that you have the correct structure:\n",
    "\n",
    "**Windows:**\n",
    "```powershell\n",
    "ls train128\n",
    "ls test128\n",
    "```\n",
    "\n",
    "**Mac/Linux:**\n",
    "```bash\n",
    "ls train128\n",
    "ls test128\n",
    "```\n",
    "\n",
    "**Expected structure:**\n",
    "```\n",
    "3lc-chihuahua-muffin-starter/\n",
    "‚îú‚îÄ‚îÄ train128/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ chihuahua/     (100 images)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ muffin/        (100 images)\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ undefined/     (4,533 unlabeled images)\n",
    "‚îú‚îÄ‚îÄ test128/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ chihuahua/     (640 images)\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ muffin/        (544 images)\n",
    "‚îî‚îÄ‚îÄ starter_notebook.ipynb (this file)\n",
    "```\n",
    "\n",
    "‚úÖ **If you see these folders with images, you're ready to proceed!**\n",
    "\n",
    "---\n",
    "\n",
    "### Step 1: Create a 3LC Account (required for all teams and participants)\n",
    "1. Go to [https://account.3lc.ai](https://account.3lc.ai)\n",
    "2. Create your account (a workspace is auto-created for you)\n",
    "3. Get your API key from [https://account.3lc.ai/api-key](https://account.3lc.ai/api-key)\n",
    "\n",
    "   <div align=\"left\">\n",
    "   <img src=\"content/api.png\" alt=\"Description\" width=\"600\">\n",
    "   </div>\n",
    "\n",
    "For Video tutorial refer [Here](https://docs.3lc.ai/3lc/latest/quickstart/quickstart.html)\n",
    "\n",
    "### Step 2: Set Up Python Environment (activate every time you run notebook/scripts)\n",
    "\n",
    "**Option A: Using venv (Recommended)**\n",
    "\n",
    "Open a command prompt/terminal and run:\n",
    "\n",
    "```bash\n",
    "# Windows\n",
    "python -m venv 3lc-env\n",
    "3lc-env\\Scripts\\activate\n",
    "\n",
    "# Linux/Mac\n",
    "python -m venv 3lc-env\n",
    "source 3lc-env/bin/activate\n",
    "\n",
    "# Install 3LC (includes PyTorch, torchvision, and all dependencies)\n",
    "pip install 3lc\n",
    "pip install joblib pacmap\n",
    "```\n",
    "\n",
    "**Option B: Using Conda**\n",
    "```bash\n",
    "conda create -n 3lc-env python=3.10 -y\n",
    "conda activate 3lc-env\n",
    "pip install 3lc\n",
    "pip install joblib pacmap\n",
    "```\n",
    "\n",
    "### Step 3: GPU Setup (Optional but Recommended)\n",
    "\n",
    "If you have a GPU, reinstall PyTorch with CUDA support for 10x faster training:\n",
    "```bash\n",
    "# For CUDA 11.8\n",
    "pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# For CUDA 12.1\n",
    "pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121\n",
    "```\n",
    "Visit [PyTorch.org](https://pytorch.org/get-started/locally/) to find the right command for your CUDA version.\n",
    "\n",
    "### Step 4: Login to 3LC (Only required once)\n",
    "\n",
    "Use the 3lc login command to connect your use of the package with your 3LC account workspace using an API key.\n",
    "Open a command prompt/terminal (with your environment activated) and run:\n",
    "\n",
    "```bash\n",
    "3lc login <your_api_key>\n",
    "```\n",
    "\n",
    "Replace `<your_api_key>` with your actual API key from Step 1. This saves your credentials locally - you only need to do this once!\n",
    "\n",
    "### Step 5: Start 3LC Service (Optional - Required for Dashboard visualization)\n",
    "\n",
    "**Important:** The service is NOT required for training scripts to run, but it IS required to view results in the 3LC Dashboard.\n",
    "\n",
    "We recommend starting it in the background. Open a **new/separate** command prompt/terminal window and type:\n",
    "\n",
    "```bash\n",
    "3lc service\n",
    "```\n",
    "   <div align=\"left\">\n",
    "   <img src=\"content/service.png\" alt=\"Description\" width=\"600\">\n",
    "   </div>\n",
    "\n",
    "Keep this terminal window open while you work. The service can be stopped by pressing `Q`.\n",
    "\n",
    "To view your results, open the Dashboard at [https://dashboard.3lc.ai](https://dashboard.3lc.ai)\n",
    "\n",
    "---\n",
    "\n",
    "### Quick Checklist:\n",
    "- ‚úÖ Dataset downloaded and placed in the correct location\n",
    "- ‚úÖ 3LC account created\n",
    "- ‚úÖ Python environment activated  \n",
    "- ‚úÖ Packages installed (`pip install 3lc`, `pip install joblib pacmap`)\n",
    "- ‚úÖ Logged in to 3LC (`3lc login <api_key>`)\n",
    "- ‚úÖ Service running (`3lc service`) - optional but recommended for Dashboard\n",
    "- ‚úÖ Kernel set to `3lc-env`\n",
    "\n",
    "### üìù Important Notes:\n",
    "\n",
    "**For future sessions:** You only need to:\n",
    "1. Activate your environment (Step 2)\n",
    "2. Optionally start the service in a separate terminal (Step 5)\n",
    "\n",
    "**Setting Kernel:** Make sure you are using the `3lc-env` kernel.:\n",
    "- Click \"Kernel\" ‚Üí \"Change Kernel\" ‚Üí Select `3lc-env`\n",
    "\n",
    "**Ready? Run the cells below in order!** üöÄ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25af91e1872c4c0",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 1: Environment Verification & Dataset Registration\n",
    "\n",
    "Let's verify your setup and register the dataset with 3LC.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "84a2bf66bf2073f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T23:40:24.908685Z",
     "start_time": "2025-11-19T23:40:24.902194Z"
    }
   },
   "source": [
    "# Imports \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import tlc\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: C:\\Users\\juhee\\Desktop\\Hackathon\\3lc-env\\Scripts\\python.exe\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "2d4e72da2d509cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T23:40:38.902407Z",
     "start_time": "2025-11-19T23:40:38.890256Z"
    }
   },
   "source": [
    "# ============================================================================\n",
    "# ENVIRONMENT VERIFICATION\n",
    "# ============================================================================\n",
    "print(\"Environment Check:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check CUDA\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"[OK] CUDA available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"     GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"[WARNING] CUDA not available - training will use CPU (slower)\")\n",
    "\n",
    "print(f\"[OK] Using device: {device}\")\n",
    "print(\"=\" * 70)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Check:\n",
      "======================================================================\n",
      "PyTorch version: 2.5.1+cu121\n",
      "[OK] CUDA available: NVIDIA GeForce RTX 4070\n",
      "     GPU Memory: 12.0 GB\n",
      "[OK] Using device: cuda\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "088bca75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T23:40:46.414996Z",
     "start_time": "2025-11-19T23:40:46.253525Z"
    }
   },
   "source": [
    "# ============================================================================\n",
    "# DATASET VERIFICATION\n",
    "# ============================================================================\n",
    "print(\"\\nDataset Check:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check for required directories\n",
    "train_dir = Path(\"train128\")\n",
    "test_dir = Path(\"test128\")\n",
    "classes_to_check = [\"chihuahua\", \"muffin\", \"undefined\"]\n",
    "\n",
    "if not train_dir.exists() or not test_dir.exists():\n",
    "    print(\"[ERROR] Dataset not found!\")\n",
    "    print(f\"  Expected 'train128' and 'test128' folders in: {Path('.').absolute()}\")\n",
    "    print(\"\\n  Please download the dataset and place it in the same directory as this notebook.\")\n",
    "    print(\"  See Step 0 in the instructions above for details.\")\n",
    "    raise FileNotFoundError(\"Dataset directories not found\")\n",
    "\n",
    "# Count images in each split\n",
    "total_train = 0\n",
    "total_test = 0\n",
    "\n",
    "for class_name in classes_to_check:\n",
    "    train_class = train_dir / class_name\n",
    "    test_class = test_dir / class_name\n",
    "    \n",
    "    if train_class.exists():\n",
    "        train_count = len(list(train_class.glob('*.jpg')))\n",
    "        total_train += train_count\n",
    "        print(f\"[OK] train128/{class_name}: {train_count} images\")\n",
    "    else:\n",
    "        print(f\"[WARNING] train128/{class_name}: folder not found\")\n",
    "    \n",
    "    if test_class.exists():\n",
    "        test_count = len(list(test_class.glob('*.jpg')))\n",
    "        total_test += test_count\n",
    "        print(f\"[OK] test128/{class_name}: {test_count} images\")\n",
    "    else:\n",
    "        print(f\"[WARNING] test128/{class_name}: folder not found\")\n",
    "\n",
    "print(f\"\\n[OK] Total training images: {total_train}\")\n",
    "print(f\"[OK] Total test images: {total_test}\")\n",
    "print(\"=\" * 70)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Check:\n",
      "======================================================================\n",
      "[OK] train128/chihuahua: 100 images\n",
      "[OK] test128/chihuahua: 640 images\n",
      "[OK] train128/muffin: 100 images\n",
      "[OK] test128/muffin: 544 images\n",
      "[OK] train128/undefined: 4533 images\n",
      "[WARNING] test128/undefined: folder not found\n",
      "\n",
      "[OK] Total training images: 4733\n",
      "[OK] Total test images: 1184\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "956eb75d4555ceaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T23:40:56.848391Z",
     "start_time": "2025-11-19T23:40:52.050070Z"
    }
   },
   "source": [
    "# ============================================================================\n",
    "# DATASET REGISTRATION \n",
    "# ============================================================================\n",
    "\n",
    "# Define constants\n",
    "CLASSES = [\"chihuahua\", \"muffin\", \"undefined\"]\n",
    "PROJECT_NAME = \"Chihuahua-Muffin\"\n",
    "DATASET_NAME = \"chihuahua-muffin\"\n",
    "\n",
    "# Define schemas\n",
    "schemas = {\n",
    "    \"id\": tlc.Schema(value=tlc.Int32Value(), writable=False),\n",
    "    \"image\": tlc.ImagePath,\n",
    "    \"label\": tlc.CategoricalLabel(\"label\", classes=CLASSES),\n",
    "    \"weight\": tlc.SampleWeightSchema(),\n",
    "}\n",
    "\n",
    "def register_dataset_to_table(dataset_path, table_name, split_name):\n",
    "    \"\"\"\n",
    "    Register images from a folder structure to a 3LC table.\n",
    "    EXACT function from register_tables.py\n",
    "    \"\"\"\n",
    "    dataset_path = Path(dataset_path)\n",
    "    image_data = []\n",
    "    \n",
    "    # Collect all images with their labels\n",
    "    for class_idx, class_name in enumerate(CLASSES):\n",
    "        class_folder = dataset_path / class_name\n",
    "        if class_folder.exists():\n",
    "            image_files = sorted(class_folder.glob('*.jpg'))\n",
    "            print(f\"Found {len(image_files)} images in {class_name} folder for {split_name} set\")\n",
    "            \n",
    "            for img_path in image_files:\n",
    "                image_data.append({\n",
    "                    'path': str(img_path.absolute()),\n",
    "                    'label': class_idx,\n",
    "                })\n",
    "        else:\n",
    "            print(f\"Warning: {class_folder} does not exist\")\n",
    "    \n",
    "    print(f\"\\nTotal images for {split_name} set: {len(image_data)}\")\n",
    "    print(f\"  - Chihuahua: {sum(1 for x in image_data if x['label'] == 0)}\")\n",
    "    print(f\"  - Muffin: {sum(1 for x in image_data if x['label'] == 1)}\")\n",
    "    print(f\"  - Undefined: {sum(1 for x in image_data if x['label'] == 2)}\")\n",
    "    \n",
    "    # Create table writer\n",
    "    table_writer = tlc.TableWriter(\n",
    "        table_name=table_name,\n",
    "        dataset_name=DATASET_NAME,\n",
    "        project_name=PROJECT_NAME,\n",
    "        description=f\"Chihuahua vs Muffin {split_name} set with {len(image_data)} images\",\n",
    "        column_schemas=schemas,\n",
    "        if_exists=\"overwrite\",\n",
    "    )\n",
    "    \n",
    "    # Add rows to the table\n",
    "    for i, data in enumerate(image_data):\n",
    "        label = data['label']\n",
    "        weight = 1.0 if label in [0, 1] else 0.0\n",
    "        \n",
    "        table_writer.add_row({\n",
    "            \"id\": i,\n",
    "            \"image\": data['path'],\n",
    "            \"label\": label,\n",
    "            \"weight\": weight,\n",
    "        })\n",
    "    \n",
    "    # Finalize the table\n",
    "    table = table_writer.finalize()\n",
    "    \n",
    "    print(f\"\\n[OK] Created 3LC table: '{table_name}' with {len(image_data)} samples\")\n",
    "    print(f\"  Table URL: {table.url}\")\n",
    "    \n",
    "    return table\n",
    "\n",
    "# Base path\n",
    "base_path = Path(\".\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Registering Chihuahua vs Muffin Dataset in 3LC Tables\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Register train set\n",
    "print(\"\\n[1/2] Registering TRAIN set...\")\n",
    "print(\"-\" * 60)\n",
    "train_path = base_path / 'train128'\n",
    "train_table = register_dataset_to_table(train_path, 'train', 'train')\n",
    "\n",
    "# Register test set\n",
    "print(\"\\n[2/2] Registering TEST set...\")\n",
    "print(\"-\" * 60)\n",
    "test_path = base_path / 'test128'\n",
    "test_table = register_dataset_to_table(test_path, 'test', 'test')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"[OK] Successfully registered both tables!\")\n",
    "print(\"=\" * 60)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Registering Chihuahua vs Muffin Dataset in 3LC Tables\n",
      "============================================================\n",
      "\n",
      "[1/2] Registering TRAIN set...\n",
      "------------------------------------------------------------\n",
      "Found 100 images in chihuahua folder for train set\n",
      "Found 100 images in muffin folder for train set\n",
      "Found 4533 images in undefined folder for train set\n",
      "\n",
      "Total images for train set: 4733\n",
      "  - Chihuahua: 100\n",
      "  - Muffin: 100\n",
      "  - Undefined: 4533\n",
      "\n",
      "[OK] Created 3LC table: 'train' with 4733 samples\n",
      "  Table URL: C:/Users/juhee/AppData/Local/3LC/3LC/projects/Chihuahua-Muffin/datasets/chihuahua-muffin/tables/train\n",
      "\n",
      "[2/2] Registering TEST set...\n",
      "------------------------------------------------------------\n",
      "Found 640 images in chihuahua folder for test set\n",
      "Found 544 images in muffin folder for test set\n",
      "Warning: test128\\undefined does not exist\n",
      "\n",
      "Total images for test set: 1184\n",
      "  - Chihuahua: 640\n",
      "  - Muffin: 544\n",
      "  - Undefined: 0\n",
      "\n",
      "[OK] Created 3LC table: 'test' with 1184 samples\n",
      "  Table URL: C:/Users/juhee/AppData/Local/3LC/3LC/projects/Chihuahua-Muffin/datasets/chihuahua-muffin/tables/test\n",
      "\n",
      "============================================================\n",
      "[OK] Successfully registered both tables!\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "e95593546680a6e8",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 2: Model Definition & Training Setup\n",
    "\n",
    "Now we'll define our ResNet-18 model and prepare for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76a785b81d72298c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Model and transforms defined\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# MODEL DEFINITION \n",
    "# ============================================================================\n",
    "\n",
    "class ResNet18Classifier(nn.Module):\n",
    "    \"\"\"ResNet-18 model for classification (no pretrained weights)\"\"\"\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(ResNet18Classifier, self).__init__()\n",
    "        # Load ResNet-18 without pretrained weights\n",
    "        self.resnet = models.resnet18(weights=None)\n",
    "        \n",
    "        # Get the number of features from ResNet's final layer\n",
    "        resnet_features = self.resnet.fc.in_features\n",
    "        \n",
    "        # Remove the original final layer\n",
    "        self.resnet.fc = nn.Identity()\n",
    "        \n",
    "        # Create new classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(resnet_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Get ResNet features (without final classification layer)\n",
    "        resnet_features = self.resnet(x)\n",
    "        # Pass through classification head\n",
    "        return self.classifier(resnet_features)\n",
    "\n",
    "# Transforms \n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.RandomCrop(128),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.CenterCrop(128),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def train_fn(sample):\n",
    "    \"\"\"Transform function for training \"\"\"\n",
    "    image = Image.open(sample['image'])\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "    return train_transform(image), sample['label']\n",
    "\n",
    "def val_fn(sample):\n",
    "    \"\"\"Transform function for validation \"\"\"\n",
    "    image = Image.open(sample['image'])\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "    return val_transform(image), sample['label']\n",
    "\n",
    "print(\"[OK] Model and transforms defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f56451d1ca98f607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Metrics function defined\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# METRICS FUNCTION \n",
    "# ============================================================================\n",
    "\n",
    "def metrics_fn(batch, predictor_output: tlc.PredictorOutput):\n",
    "    \"\"\"Metrics function for 3LC collection\"\"\"\n",
    "    labels = batch[1].to(device)\n",
    "    predictions = predictor_output.forward\n",
    "    \n",
    "    # Softmax for probabilities\n",
    "    softmax_output = F.softmax(predictions, dim=1)\n",
    "    predicted_indices = torch.argmax(predictions, dim=1)\n",
    "    confidence = torch.gather(softmax_output, 1, predicted_indices.unsqueeze(1)).squeeze(1)\n",
    "    accuracy = (predicted_indices == labels).float()\n",
    "    \n",
    "    # Compute loss, set to 1.0 for labels outside valid range\n",
    "    valid_labels = labels < predictions.shape[1]\n",
    "    cross_entropy_loss = torch.ones_like(labels, dtype=torch.float32)\n",
    "    cross_entropy_loss[valid_labels] = nn.CrossEntropyLoss(reduction=\"none\")(\n",
    "        predictions[valid_labels], labels[valid_labels]\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"loss\": cross_entropy_loss.cpu().numpy(),\n",
    "        \"predicted\": predicted_indices.cpu().numpy(),\n",
    "        \"accuracy\": accuracy.cpu().numpy(),\n",
    "        \"confidence\": confidence.cpu().numpy(),\n",
    "    }\n",
    "\n",
    "print(\"[OK] Metrics function defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d517956af6f7b48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded table with 4733 samples\n",
      "['chihuahua', 'muffin', 'undefined']\n",
      "Using layer 67 for embeddings collection\n",
      "[OK] Training setup complete\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TRAINING SETUP \n",
    "# ============================================================================\n",
    "\n",
    "# Settings\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "print(f\"Loaded table with {len(train_table)} samples\")\n",
    "class_names = list(train_table.get_simple_value_map(\"label\").values())\n",
    "print(class_names)\n",
    "\n",
    "# Apply map functions \n",
    "train_table.map(train_fn).map_collect_metrics(val_fn)\n",
    "test_table.map(val_fn)\n",
    "\n",
    "# Create sampler \n",
    "sampler = train_table.create_sampler(exclude_zero_weights=True)\n",
    "\n",
    "# Create dataloaders \n",
    "train_dataloader = DataLoader(\n",
    "    train_table,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sampler=sampler,\n",
    "    num_workers=0,  # Important for Windows compatibility\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    test_table,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "# Initialize model \n",
    "model = ResNet18Classifier(num_classes=len(class_names)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Initialize 3LC run \n",
    "run = tlc.init(\n",
    "    project_name=train_table.project_name,\n",
    "    description=\"Finetuning classifier for active learning\"\n",
    ")\n",
    "\n",
    "# Metric schemas \n",
    "metric_schemas = {\n",
    "    \"loss\": tlc.Schema(\n",
    "        description=\"Cross entropy loss\",\n",
    "        value=tlc.Float32Value(),\n",
    "    ),\n",
    "    \"predicted\": tlc.CategoricalLabelSchema(\n",
    "        display_name=\"predicted label\",\n",
    "        classes=class_names,\n",
    "    ),\n",
    "    \"accuracy\": tlc.Schema(\n",
    "        description=\"Per-sample accuracy\",\n",
    "        value=tlc.Float32Value(),\n",
    "    ),\n",
    "    \"confidence\": tlc.Schema(\n",
    "        description=\"Prediction confidence\",\n",
    "        value=tlc.Float32Value(),\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Create metrics collector \n",
    "classification_metrics_collector = tlc.FunctionalMetricsCollector(\n",
    "    collection_fn=metrics_fn,\n",
    "    column_schemas=metric_schemas,\n",
    ")\n",
    "\n",
    "# Find embeddings layer \n",
    "indices_and_modules = list(enumerate(model.resnet.named_modules()))\n",
    "resnet_fc_layer_index = None\n",
    "for idx, (name, _) in indices_and_modules:\n",
    "    if name == 'fc':\n",
    "        resnet_fc_layer_index = idx\n",
    "        break\n",
    "\n",
    "if resnet_fc_layer_index is None:\n",
    "    resnet_fc_layer_index = len(indices_and_modules) - 1\n",
    "\n",
    "print(f\"Using layer {resnet_fc_layer_index} for embeddings collection\")\n",
    "\n",
    "# Create embeddings collector and predictor \n",
    "embeddings_metrics_collector = tlc.EmbeddingsMetricsCollector(layers=[resnet_fc_layer_index])\n",
    "predictor = tlc.Predictor(model, layers=[resnet_fc_layer_index])\n",
    "\n",
    "print(\"[OK] Training setup complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1523e459e1143588",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 3: Training Loop\n",
    "\n",
    "Now we'll train the model and track everything with 3LC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bce261e69e2ae2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 18.95it/s, loss=0.979]\n",
      "Validation Epoch 1/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 74/74 [00:02<00:00, 30.33it/s, val_loss=24.6]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Val Loss: 13.3647, Val Accuracy: 54.05%\n",
      "  [OK] New best model! Validation accuracy: 54.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 18.77it/s, loss=0.808]\n",
      "Validation Epoch 2/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 74/74 [00:02<00:00, 29.43it/s, val_loss=47.5]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Val Loss: 23.4807, Val Accuracy: 56.25%\n",
      "  [OK] New best model! Validation accuracy: 56.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 19.57it/s, loss=0.816]\n",
      "Validation Epoch 3/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 74/74 [00:02<00:00, 29.92it/s, val_loss=4.62]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - Val Loss: 3.2857, Val Accuracy: 70.69%\n",
      "  [OK] New best model! Validation accuracy: 70.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 19.76it/s, loss=0.409]\n",
      "Validation Epoch 4/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 74/74 [00:02<00:00, 30.39it/s, val_loss=0.141] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - Val Loss: 0.6082, Val Accuracy: 82.94%\n",
      "  [OK] New best model! Validation accuracy: 82.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 18.76it/s, loss=0.519]\n",
      "Validation Epoch 5/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 74/74 [00:02<00:00, 27.79it/s, val_loss=0.945] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Val Loss: 0.7367, Val Accuracy: 78.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 19.16it/s, loss=0.246]\n",
      "Validation Epoch 6/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 74/74 [00:02<00:00, 25.52it/s, val_loss=0.269] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - Val Loss: 0.6561, Val Accuracy: 78.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 17.01it/s, loss=0.521]\n",
      "Validation Epoch 7/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 74/74 [00:02<00:00, 24.69it/s, val_loss=0.553]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - Val Loss: 0.8068, Val Accuracy: 74.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 16.67it/s, loss=0.17] \n",
      "Validation Epoch 8/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 74/74 [00:02<00:00, 25.51it/s, val_loss=0.524] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 - Val Loss: 0.4936, Val Accuracy: 80.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 18.12it/s, loss=0.111]\n",
      "Validation Epoch 9/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 74/74 [00:02<00:00, 28.62it/s, val_loss=0.587]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 - Val Loss: 0.5880, Val Accuracy: 81.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 19.79it/s, loss=0.433]\n",
      "Validation Epoch 10/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 74/74 [00:02<00:00, 29.95it/s, val_loss=0.0345] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Val Loss: 1.0829, Val Accuracy: 57.09%\n",
      "\n",
      "============================================================\n",
      "Training complete!\n",
      "Best validation accuracy: 82.94%\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TRAINING LOOP \n",
    "# ============================================================================\n",
    "\n",
    "best_val_accuracy = 0.0\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    progress_bar = tqdm(train_dataloader, desc=f'Epoch {epoch+1}/{EPOCHS}')\n",
    "    for images, labels in progress_bar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "    model.eval()\n",
    "    # Run standard validation\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    val_progress_bar = tqdm(val_dataloader, desc=f'Validation Epoch {epoch+1}/{EPOCHS}')\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_progress_bar:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            val_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "            val_progress_bar.set_postfix({'val_loss': loss.item()})\n",
    "        \n",
    "    # Calculate epoch metrics\n",
    "    val_avg_loss = val_loss / len(val_dataloader)\n",
    "    val_accuracy = 100 * val_correct / val_total\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Val Loss: {val_avg_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        print(f\"  [OK] New best model! Validation accuracy: {best_val_accuracy:.2f}%\")\n",
    "    \n",
    "    # Log to 3LC\n",
    "    tlc.log({\n",
    "        \"epoch\": epoch,\n",
    "        \"val_loss\": val_avg_loss,\n",
    "        \"val_accuracy\": val_accuracy,\n",
    "    })\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Training complete!\")\n",
    "print(f\"Best validation accuracy: {best_val_accuracy:.2f}%\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a88c97d7cc94652",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 4: Metrics Collection\n",
    "\n",
    "Now we'll collect per-sample metrics using the best model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35af28cc39957b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c520aec7244945bc89042181dff7b6be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OK] Loaded best model for metrics collection\n",
      "[OK] Best model saved to 'resnet18_classifier_best.pth'\n",
      "\n",
      "Collecting metrics on train set with best model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OK] Metrics collection complete!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# METRICS COLLECTION \n",
    "# ============================================================================\n",
    "\n",
    "# Load best model\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(\"\\n[OK] Loaded best model for metrics collection\")\n",
    "\n",
    "# Save best model\n",
    "torch.save(model.state_dict(), 'resnet18_classifier_best.pth')\n",
    "print(\"[OK] Best model saved to 'resnet18_classifier_best.pth'\")\n",
    "\n",
    "# Collect metrics\n",
    "print(\"\\nCollecting metrics on train set with best model...\")\n",
    "model.eval()\n",
    "tlc.collect_metrics(\n",
    "    train_table,\n",
    "    predictor=predictor,\n",
    "    metrics_collectors=[classification_metrics_collector, embeddings_metrics_collector],\n",
    "    split=\"train\",\n",
    "    dataloader_args={\"batch_size\": BATCH_SIZE, \"num_workers\": 0},\n",
    ")\n",
    "\n",
    "print(\"\\n[OK] Metrics collection complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5912f9e16b86808d",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 5: Embeddings Reduction\n",
    "\n",
    "Finally, we'll reduce the embeddings for 3D visualization in the Dashboard.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "481fceaee79fe244",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pacmap.pacmap:Note: `n_components != 2` have not been thoroughly tested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reducing embeddings using PaCMAP...\n",
      "Embeddings reduction complete!\n",
      "\n",
      "============================================================\n",
      "[OK] Complete! View results at https://dashboard.3lc.ai\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EMBEDDINGS REDUCTION \n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nReducing embeddings using PaCMAP...\")\n",
    "run.reduce_embeddings_by_foreign_table_url(\n",
    "    train_table.url,\n",
    "    method=\"pacmap\",\n",
    "    n_neighbors=2,\n",
    "    n_components=3,\n",
    ")\n",
    "print(\"Embeddings reduction complete!\")\n",
    "\n",
    "run.set_status_completed()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"[OK] Complete! View results at https://dashboard.3lc.ai\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daad505d615c97e",
   "metadata": {},
   "source": [
    "---\n",
    "# üéâ Training Complete!\n",
    "\n",
    "## What You've Accomplished:\n",
    "‚úÖ **Registered dataset** with 3LC Tables for version control  \n",
    "‚úÖ **Trained ResNet-18** classifier with full 3LC integration  \n",
    "‚úÖ **Collected metrics** - per-sample loss, accuracy, confidence, embeddings  \n",
    "‚úÖ **Created 3LC Run** - visible in Dashboard with complete tracking  \n",
    "\n",
    "## Next Steps: The Train-Fix-Retrain Loop\n",
    "\n",
    "### 1. Analyze Your Results in 3LC Dashboard\n",
    "\n",
    "Open [https://dashboard.3lc.ai](https://dashboard.3lc.ai) and navigate to your project: `Chihuahua-Muffin`\n",
    "\n",
    "**What to Look For:**\n",
    "- **Low-confidence predictions** - Model is uncertain filter embeddings\n",
    "- **High-loss samples** - Model performs poorly  \n",
    "- **Outliers in embeddings** - Potentially mislabeled or ambiguous\n",
    "- **Class confusion patterns** - Which classes are confused?\n",
    "\n",
    "### 2. Identify Data Quality Issues\n",
    "\n",
    "Common issues to fix:\n",
    "- **Wrong labels** - Chihuahua labeled as Muffin or vice versa\n",
    "- **Poor quality images** - Blurry, corrupted, or irrelevant\n",
    "- **Ambiguous cases** - Move to \"undefined\" class for later review\n",
    "\n",
    "### 3. Fix Data in Dashboard\n",
    "\n",
    "3LC Dashboard allows you to:\n",
    "- **Edit labels** directly on images\n",
    "- **Add/remove samples** from training set\n",
    "- **Adjust sample weights** to focus on hard examples\n",
    "- **Create filtered views** to find problematic samples\n",
    "\n",
    "**Learn more:** [Edit Tables in Dashboard](https://docs.3lc.ai/3lc/latest/how-to/basics/edit-table.html)\n",
    "\n",
    "### 4. Retrain with Improved Data\n",
    "\n",
    "After editing in Dashboard:\n",
    "1. The Dashboard creates a **new table version** automatically\n",
    "2. **Rerun cells 5-15** (from dataset registration through embeddings)\n",
    "3. 3LC automatically uses the latest version with your edits if you use the .latest() method\n",
    "4. Compare runs in Dashboard to see improvement!\n",
    "\n",
    "**Pro Tip:** Change the `description` parameter in `tlc.init()` (Cell 9) to track different iterations (e.g., \"baseline_v1\", \"fixed_labels_v2\")\n",
    "\n",
    "### 5. Iterate for Maximum Performance\n",
    "\n",
    "Each iteration should:\n",
    "- Fix a specific type of error\n",
    "- Document what you changed\n",
    "- Measure improvement in validation accuracy\n",
    "- Identify next bottleneck\n",
    "\n",
    "**This iterative process is data-centric AI in action!**\n",
    "\n",
    "---\n",
    "\n",
    "## Resources & Support:\n",
    "\n",
    "### Documentation:\n",
    "- [3LC Documentation](https://docs.3lc.ai)\n",
    "- [3LC Dashboard Guide](https://docs.3lc.ai/3lc/latest/user-guide/dashboard/)\n",
    "- [PyTorch Documentation](https://pytorch.org/docs/)\n",
    "\n",
    "### 3LC Dashboard:\n",
    "- [Open Dashboard](https://dashboard.3lc.ai)\n",
    "- View your project: `Chihuahua-Muffin`\n",
    "- Explore runs, metrics, and embeddings\n",
    "\n",
    "### Need Help?\n",
    "- Check the documentation links above\n",
    "- Ask hackathon organizers\n",
    "- Review the example scripts (`register_tables.py`, `train.py`)\n",
    "\n",
    "---\n",
    "\n",
    "## Professional Skills You're Developing:\n",
    "\n",
    "‚úÖ **Data-Centric AI** - Using model feedback to improve data quality  \n",
    "‚úÖ **Experiment Tracking** - Systematic approach to model development  \n",
    "‚úÖ **Iterative Improvement** - Train-fix-retrain methodology  \n",
    "‚úÖ **Production Workflows** - How real AI teams work\n",
    "\n",
    "**These are the skills that separate good ML engineers from great ones!**\n",
    "\n",
    "---\n",
    "\n",
    "**Ready to improve your model? Open the Dashboard and start analyzing!** üöÄ\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
